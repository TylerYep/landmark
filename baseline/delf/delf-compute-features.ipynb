{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import glob\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "import cv2\n",
    "\n",
    "from delf import feature_io\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.spatial import cKDTree\n",
    "from skimage.feature import plot_matches\n",
    "from skimage.measure import ransac\n",
    "from skimage.transform import AffineTransform\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from tensorflow.python.platform import app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_path = './train-highres/'\n",
    "non_landmark_train_path = './distractors/*/'\n",
    "dev_path = './dev/'\n",
    "non_landmark_dev_path = './distractors-dev/'\n",
    "test_path = './test-highres/'\n",
    "\n",
    "_DISTANCE_THRESHOLD = 0.8\n",
    "\n",
    "input_shape = (384, 384)\n",
    "\n",
    "n_cat = 14942"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_files = glob.glob(train_path + '*.jpg')\n",
    "train_image_ids = [image_file.replace(\n",
    "    '.jpg', '').replace(train_path, '') for image_file in train_image_files]\n",
    "train_info_full = pd.read_csv('train.csv', index_col='id')\n",
    "train_info_full.head()\n",
    "train_info = train_info_full.loc[train_image_ids]\n",
    "train_info['filename'] = pd.Series(train_image_files, index=train_image_ids)\n",
    "\n",
    "train_info_correct = pd.read_csv('train_info_correct.csv', index_col='id')\n",
    "train_info = train_info[train_info['landmark_id'].isin(train_info_correct['landmark_id'])]\n",
    "\n",
    "train_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_landmark_image_files = glob.glob(non_landmark_train_path+'*.jp*g')\n",
    "nlm_df = pd.DataFrame({'filename':non_landmark_image_files})\n",
    "nlm_df['landmark_id'] = -1\n",
    "print(len(nlm_df))\n",
    "nlm_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cat_train = train_info['landmark_id'].nunique()\n",
    "print(n_cat_train)\n",
    "if n_cat_train != n_cat:\n",
    "    warnings.warn('Warning: The training data is not compatible.')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_image_files = glob.glob(dev_path + '*.jpg')\n",
    "dev_image_ids = [image_file.replace(\n",
    "    '.jpg', '').replace(dev_path, '') for image_file in dev_image_files]\n",
    "dev_info = train_info_full.loc[dev_image_ids]\n",
    "dev_info['filename'] = pd.Series(dev_image_files, index=dev_image_ids)\n",
    "#dev_info=dev_info[dev_info['landmark_id'].isin(train_info['landmark_id'])]\n",
    "dev_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_landmark_dev_image_files = glob.glob(non_landmark_dev_path+'*.jpg')\n",
    "nlm_dev_df = pd.DataFrame({'filename': non_landmark_dev_image_files})\n",
    "nlm_dev_df['landmark_id'] = -1\n",
    "print(len(nlm_dev_df))\n",
    "nlm_dev_df.index = [str(i) for i in nlm_dev_df.index]\n",
    "nlm_dev_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_info_full = pd.read_csv('test.csv', index_col='id')\n",
    "test_info_full.head()\n",
    "\n",
    "test_image_files = glob.glob(test_path+'*.jpg')\n",
    "test_image_ids = [image_file.replace(\n",
    "    '.jpg', '').replace(test_path, '') for image_file in test_image_files]\n",
    "\n",
    "test_info=test_info_full.loc[test_image_ids]\n",
    "test_info['filename'] = pd.Series(test_image_files, index=test_image_ids)\n",
    "\n",
    "test_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Landmark_id of image\", train_image_files[0], \":\", \n",
    "      train_info.loc[train_image_ids[0]]['landmark_id'])\n",
    "print(train_info[\"landmark_id\"].max())\n",
    "testimg = cv2.cvtColor(cv2.imread(np.random.choice(train_image_files)), \n",
    "                     cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(testimg)\n",
    "testimg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_delf_features(info, odir, start_i=0):\n",
    "    def image_input_fn():\n",
    "        filename_queue = tf.train.string_input_producer(\n",
    "          info['filename'].values.tolist(), shuffle=False)\n",
    "        reader = tf.WholeFileReader()\n",
    "        _, value = reader.read(filename_queue)\n",
    "        image_tf_raw = tf.image.decode_jpeg(value, channels=3)\n",
    "        image_tf = tf.image.resize_images(image_tf_raw, [224, 224])\n",
    "        return tf.image.convert_image_dtype(image_tf, tf.float32)\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    tf.logging.set_verbosity(tf.logging.FATAL)\n",
    "\n",
    "    m = hub.Module('https://tfhub.dev/google/delf/1')\n",
    "\n",
    "    # The module operates on a single image at a time, so define a placeholder to\n",
    "    # feed an arbitrary image in.\n",
    "    image_placeholder = tf.placeholder(\n",
    "        tf.float32, shape=(input_shape[0], input_shape[1], 3), name='input_image')\n",
    "\n",
    "    module_inputs = {\n",
    "        'image': image_placeholder,\n",
    "        'score_threshold': 100.0,\n",
    "        'image_scales': [0.25, 0.3536, 0.5, 0.7071, 1.0, 1.4142, 2.0],\n",
    "        'max_feature_num': 1000,\n",
    "    }\n",
    "\n",
    "    module_outputs = m(module_inputs, as_dict=True)\n",
    "\n",
    "    with tf.Session() as sess:        \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for i in range(start_i,len(info)):\n",
    "            fname = info.iloc[i]['filename']\n",
    "            img_id = info.index[i]\n",
    "#            print(fname)\n",
    "            try:\n",
    "                img = cv2.cvtColor(\n",
    "                      cv2.resize(cv2.imread(fname),input_shape),\n",
    "                      cv2.COLOR_BGR2RGB) / 255.\n",
    "            except:\n",
    "                warnings.warn('Warning: could not read image: ' \n",
    "                              + fname +\n",
    "                              '. Use black img instead.')\n",
    "                img = np.zeros((input_shape[0], input_shape[1], 3), dtype=np.float32)\n",
    "                \n",
    "            locations, descriptions = sess.run(\n",
    "                [module_outputs['locations'],  module_outputs['descriptors']],\n",
    "                feed_dict={image_placeholder: img})\n",
    "            if i % 100 == 0:\n",
    "                print(i, '/', len(info))\n",
    "                np.savetxt(odir + 'last_i.txt', np.array([i]))\n",
    "            \n",
    "            np.save(odir + img_id + '_loc.npy', locations)\n",
    "            np.save(odir + img_id + '_desc.npy', descriptions)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_ref_imgs = 48\n",
    "#def sample(df):\n",
    "#    return df.sample(min(n_ref_imgs,len(df)))\n",
    "#train_info_red=train_info.groupby('landmark_id', group_keys=False).apply(sample)\n",
    "#print(len(train_info_red))\n",
    "#train_info_red.to_csv('train_info_red_sample_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_info_red = pd.read_csv('train_info_red_sample_1.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_info_red.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_delf_features(train_info_red, 'delf-train/', start_i=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_delf_features(dev_info, 'delf-dev/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_delf_features(test_info, 'delf-test/', start_i=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_delf_features(nlm_dev_df, 'delf-nlm-dev/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
