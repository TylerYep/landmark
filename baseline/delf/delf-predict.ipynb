{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import glob\n",
    "import pickle\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import cv2\n",
    "\n",
    "from delf import feature_io\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.spatial import cKDTree\n",
    "from skimage.feature import plot_matches\n",
    "from skimage.measure import ransac\n",
    "from skimage.transform import AffineTransform\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from tensorflow.python.platform import app\n",
    "\n",
    "warnings.simplefilter('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_path = './delf-train/'\n",
    "dev_path = './delf-dev/'\n",
    "test_path = './delf-test/'\n",
    "non_landmark_dev_path = './delf-nlm-dev/'\n",
    "\n",
    "_DISTANCE_THRESHOLD = 0.8\n",
    "\n",
    "input_shape = (384, 384)\n",
    "\n",
    "n_cat = 14942"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_info = pd.read_csv('train_info_red_sample_1.csv', index_col='id')\n",
    "train_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_info_full = pd.read_csv('train.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cat_train = train_info['landmark_id'].nunique()\n",
    "print(n_cat_train)\n",
    "if n_cat_train != n_cat:\n",
    "    warnings.warn('Warning: The training data is not compatible.')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_image_files = glob.glob(dev_path + '*_loc.npy')\n",
    "dev_image_ids = [image_file.replace(\n",
    "    '_loc.npy', '').replace(dev_path, '') for image_file in dev_image_files]\n",
    "dev_info=train_info_full.loc[dev_image_ids]\n",
    "dev_info['filename'] = pd.Series(dev_image_files, index=dev_image_ids)\n",
    "#dev_info = dev_info[dev_info['landmark_id'].isin(train_info['landmark_id'])]\n",
    "dev_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_landmark_dev_image_files = glob.glob(non_landmark_dev_path + '*_loc.npy')\n",
    "nlm_dev_df = pd.DataFrame({'filename':non_landmark_dev_image_files})\n",
    "nlm_dev_df['landmark_id'] = -1\n",
    "nlm_dev_df.index = [str(i) for i in nlm_dev_df.index]\n",
    "print(len(nlm_dev_df))\n",
    "nlm_dev_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_info_full = pd.read_csv('test.csv', index_col='id')\n",
    "test_info_full.head()\n",
    "\n",
    "test_image_files = glob.glob(test_path + '*_loc.npy')\n",
    "test_image_ids = [image_file.replace(\n",
    "    '_loc.npy','').replace(test_path, '') for image_file in test_image_files]\n",
    "\n",
    "test_info=test_info_full.loc[test_image_ids]\n",
    "test_info['filename'] = pd.Series(test_image_files, index=test_image_ids)\n",
    "\n",
    "test_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = pd.read_csv('delf-scored-candidates.csv', index_col=0)\n",
    "candidates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_delf_features(img_id, ddir):\n",
    "    locations = np.load(ddir + img_id + '_loc.npy')\n",
    "    descriptions = np.load(ddir + img_id + '_desc.npy')\n",
    "    return locations, descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a1, b1 = load_delf_features(dev_info.index[1], 'delf-dev/')\n",
    "a2, b2 = load_delf_features(dev_info.index[2], 'delf-dev/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compare_imgs_1_preloaded(locations_1, \n",
    "                             descriptors_1, \n",
    "                             d1_tree, \n",
    "                             img_id_2, \n",
    "                             dir_2='delf-train/'):\n",
    "    # Read features.\n",
    "    num_features_1 = locations_1.shape[0]\n",
    "    locations_2, descriptors_2 = load_delf_features(img_id_2, dir_2)\n",
    "    num_features_2 = locations_2.shape[0]\n",
    "\n",
    "    if len(locations_1)*len(locations_2)==0:\n",
    "        return 0\n",
    "    \n",
    "    _, indices = d1_tree.query(\n",
    "            descriptors_2, \n",
    "            distance_upper_bound=_DISTANCE_THRESHOLD)\n",
    "\n",
    "    if len(indices)==0:\n",
    "        return 0\n",
    "    \n",
    "    # Select feature locations for putative matches.       \n",
    "    locations_2_to_use = np.array([\n",
    "      locations_2[i,]\n",
    "      for i in range(num_features_2)\n",
    "      if indices[i] != num_features_1\n",
    "    ])\n",
    "    locations_1_to_use = np.array([\n",
    "      locations_1[indices[i],]\n",
    "      for i in range(num_features_2)\n",
    "      if indices[i] != num_features_1\n",
    "    ])\n",
    "\n",
    "    # Perform geometric verification using RANSAC.                                                   \n",
    "    \n",
    "    if len(locations_1_to_use)*len(locations_2_to_use)==0:\n",
    "        return 0\n",
    "\n",
    "    _, inliers = ransac(\n",
    "      (locations_1_to_use, locations_2_to_use),\n",
    "      AffineTransform,\n",
    "      min_samples=3,\n",
    "      residual_threshold=20,\n",
    "      max_trials=1000)\n",
    "\n",
    "    if inliers is None:\n",
    "        score = 0.\n",
    "    else:\n",
    "        score = sum(inliers)\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compare_imgs(img_id_1, \n",
    "                 img_id_2, \n",
    "                 dir_1, dir_2='delf-train/', \n",
    "                 plot=False, \n",
    "                 img_dir_1=None, \n",
    "                 img_dir_2=None):\n",
    "    # Read features.\n",
    "    locations_1, descriptors_1 = load_delf_features(img_id_1, dir_1)\n",
    "    num_features_1 = locations_1.shape[0]\n",
    "    \n",
    "    locations_2, descriptors_2 = load_delf_features(img_id_2, dir_2)\n",
    "    num_features_2 = locations_2.shape[0]\n",
    "    \n",
    "    if len(locations_1)*len(locations_2)==0:\n",
    "        return 0\n",
    "    \n",
    "    d1_tree = cKDTree(descriptors_1)\n",
    "    _, indices = d1_tree.query(\n",
    "      descriptors_2, distance_upper_bound=_DISTANCE_THRESHOLD)\n",
    "\n",
    "    # Select feature locations for putative matches.       \n",
    "    locations_2_to_use = np.array([\n",
    "      locations_2[i,]\n",
    "      for i in range(num_features_2)\n",
    "      if indices[i] != num_features_1\n",
    "    ])\n",
    "    locations_1_to_use = np.array([\n",
    "      locations_1[indices[i],]\n",
    "      for i in range(num_features_2)\n",
    "      if indices[i] != num_features_1\n",
    "    ])\n",
    "\n",
    "    # Perform geometric verification using RANSAC.                                                   \n",
    "    if len(locations_1_to_use)*len(locations_2_to_use)==0:\n",
    "        score=0\n",
    "    else:\n",
    "        _, inliers = ransac(\n",
    "          (locations_1_to_use, locations_2_to_use),\n",
    "          AffineTransform,\n",
    "          min_samples=3,\n",
    "          residual_threshold=20,\n",
    "          max_trials=1000)\n",
    "\n",
    "        if inliers is None:\n",
    "            score = 0.\n",
    "        else:\n",
    "            score = sum(inliers)\n",
    "    \n",
    "    if plot:\n",
    "        _, ax = plt.subplots()\n",
    "        img_1=cv2.cvtColor(\n",
    "                    cv2.resize(cv2.imread(img_dir_1+img_id_1+'.jpg'),input_shape),\n",
    "                    cv2.COLOR_BGR2RGB)/255.\n",
    "        img_2=cv2.cvtColor(\n",
    "                    cv2.resize(cv2.imread(img_dir_2+img_id_2+'.jpg'),input_shape),\n",
    "                    cv2.COLOR_BGR2RGB)/255. \n",
    "        \n",
    "        inlier_idxs = np.nonzero(inliers)[0]\n",
    "        plot_matches(\n",
    "          ax,\n",
    "          img_1,\n",
    "          img_2,\n",
    "          locations_1_to_use,\n",
    "          locations_2_to_use,\n",
    "          np.column_stack((inlier_idxs, inlier_idxs)),\n",
    "          matches_color='b')\n",
    "        ax.axis('off')\n",
    "        ax.set_title('DELF correspondences')\n",
    "\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compare_features(locations_1, descriptors_1, locations_2, descriptors_2, d1_tree):\n",
    "\n",
    "    num_features_1 = locations_1.shape[0]\n",
    "    num_features_2 = locations_2.shape[0]\n",
    "    \n",
    "    if num_features_1 * num_features_2 == 0:\n",
    "        return 0\n",
    "    \n",
    "    _, indices = d1_tree.query(\n",
    "      descriptors_2, distance_upper_bound=_DISTANCE_THRESHOLD)\n",
    "\n",
    "    if len(indices)==0:\n",
    "        return 0\n",
    "    \n",
    "    # Select feature locations for putative matches.           \n",
    "    locations_2_to_use = np.array([\n",
    "      locations_2[i,]\n",
    "      for i in range(num_features_2)\n",
    "      if indices[i] != num_features_1\n",
    "    ])\n",
    "    locations_1_to_use = np.array([\n",
    "      locations_1[indices[i],]\n",
    "      for i in range(num_features_2)\n",
    "      if indices[i] != num_features_1\n",
    "    ])\n",
    "\n",
    "\n",
    "    # Perform geometric verification using RANSAC.                                                   \n",
    "    if len(locations_1_to_use) * len(locations_2_to_use) == 0:\n",
    "        return 0\n",
    "    \n",
    "    _, inliers = ransac(\n",
    "      (locations_1_to_use, locations_2_to_use),\n",
    "      AffineTransform,\n",
    "      min_samples=3,\n",
    "      residual_threshold=20,\n",
    "      max_trials=1000)\n",
    "\n",
    "    if inliers is None:\n",
    "        score = 0.\n",
    "    else:\n",
    "        score = sum(inliers)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score=compare_imgs(train_info[train_info['landmark_id'] == 6933].sample(1).index[0],\n",
    "                   train_info[train_info['landmark_id'] == 6933].sample(1).index[0], \n",
    "                   dir_1='delf-train/', \n",
    "                   dir_2='delf-train/', \n",
    "                   plot=True,\n",
    "                   img_dir_1='train-highres/', \n",
    "                   img_dir_2='train-highres/')\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def verify_hypothesis(pred_info, \n",
    "                      ref_info, \n",
    "                      pred_path, \n",
    "                      ref_path, \n",
    "                      n_imgs=8, \n",
    "                      i_start=0, \n",
    "                      io_n=100, \n",
    "                      checkpoint_n=100):\n",
    "    for i, img_id in enumerate(pred_info.index):\n",
    "        if i < i_start:\n",
    "            continue\n",
    "        hyp_id = pred_info.loc[img_id]['pred_id']\n",
    "        n_ref_imgs = sum(ref_info['landmark_id'] == hyp_id)\n",
    "        ref_img_ids = ref_info[ref_info['landmark_id'] == hyp_id].sample(\n",
    "            min(n_imgs,n_ref_imgs)).index\n",
    "        \n",
    "        try:\n",
    "            locations_1, descriptors_1 = load_delf_features(img_id, pred_path)\n",
    "        except KeyboardInterrupt:\n",
    "            raise\n",
    "        except:\n",
    "            print('Error: could not read id:', img_id, '-> Set scores to zero.')\n",
    "            pred_info.loc[img_id, 'delf_max_score']=0\n",
    "            pred_info.loc[img_id, 'delf_mean_score']=0\n",
    "            pred_info.loc[img_id, 'delf_m2_score']=0\n",
    "            continue\n",
    "        \n",
    "        d1_tree = cKDTree(descriptors_1)\n",
    "        scores = np.zeros(len(ref_img_ids))\n",
    "    \n",
    "        for j,ref_img_id in enumerate(ref_img_ids):\n",
    "            try:\n",
    "                scores[j] = compare_imgs_1_preloaded(locations_1, descriptors_1, \n",
    "                                                   d1_tree, ref_img_id, ref_path)\n",
    "            except KeyboardInterrupt:\n",
    "                raise\n",
    "            except:\n",
    "                print('An error has occured. Set score to zero.')\n",
    "        max_score = np.max(scores)\n",
    "        mean_score = np.mean(scores)\n",
    "        m2_score = np.mean(np.sort(scores)[-n_imgs//2:])\n",
    "\n",
    "        pred_info.loc[img_id, 'delf_max_score']=max_score\n",
    "        pred_info.loc[img_id, 'delf_mean_score']=mean_score\n",
    "        pred_info.loc[img_id, 'delf_m2_score']=m2_score\n",
    "\n",
    "        if i % io_n == 0:\n",
    "            print(i,'/',len(pred_info), ' -->', hyp_id, max_score, mean_score, m2_score)\n",
    "        if i % checkpoint_n == 0 and i > 0:\n",
    "            print('Checkpoint ...')\n",
    "            pred_info.to_csv('verify-chp-1.csv')\n",
    "            pred_info.to_csv('verify-chp-2.csv')\n",
    "            pred_info.to_csv('verify-chp-3.csv')\n",
    "            np.savetxt('delf-predict-last-i.txt', np.array([i]))\n",
    "            \n",
    "    return pred_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "verify_hypothesis(candidates, \n",
    "                  train_info, \n",
    "                  test_path, \n",
    "                  train_path, \n",
    "                  n_imgs=32, \n",
    "                  io_n=20, \n",
    "                  checkpoint_n=200, \n",
    "                  i_start=22000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "candidates.to_csv('delf-scored-candidates.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
